# Real-Time Anomaly Detection Pipeline
### Enterprise-Grade Data Engineering & DevOps Pattern

![Build Status](https://img.shields.io/badge/build-passing-brightgreen) ![AWS](https://img.shields.io/badge/AWS-Serverless-orange) ![Python](https://img.shields.io/badge/Python-3.9-blue) ![Infrastructure as Code](https://img.shields.io/badge/IaC-Serverless_Framework-red)

This repository demonstrates a **Production-Ready** approach to real-time data processing. Instead of relying on expensive, always-on clusters (like Databricks or EC2), this architecture utilizes **Event-Driven Serverless Compute (AWS Lambda)** and **Infrastructure as Code (IaC)** to deliver a scalable, zero-maintenance anomaly detection system.

The core framework established here serves as a **Rapid Deployment Pattern** often used for validating Proof of Concepts (PoCs) in enterprise environments, allowing teams to move from idea to deployed infrastructure in minutes.

---

## ðŸ“‹ Table of Contents
- [Business Impact & Real-World Applicability](#-business-impact--real-world-applicability)
- [Architecture Overview](#-architecture-overview)
- [Technical Skills Showcase](#-technical-skills-showcase)
- [The "PoC Accelerator" Framework](#-the-poc-accelerator-framework)
  - [Case Study: Informatica IDMC](#case-study-informatica-idmc)
- [Repository Structure](#-repository-structure)
- [Deployment Guide](#%EF%B8%8F-how-to-deploy)
- [Local Development](#-local-development)

---

## ðŸ’¼ Business Impact & Real-World Applicability

In a real-world security operations center (SOC) or high-frequency trading environment, latency and reliability are critical.

* **Cost Efficiency:** By shifting from provisioned servers to AWS Lambda, this pipeline incurs **zero cost when idle**. This pattern reduced infrastructure costs by **~90%** compared to traditional EC2-based listeners for low-to-medium throughput streams.
* **Operational Resilience:** The use of CI/CD (GitHub Actions) eliminates "it works on my machine" issues. Every deployment is automated, tested, and auditable.
* **Rapid Iteration:** The IaC setup allows new logic (e.g., changing a fraud detection threshold) to be deployed to production in **under 2 minutes** without downtime.

---

## ðŸ— Architecture Overview

The system simulates a high-throughput event stream (web traffic), processes it in micro-batches to detect bot attacks, and updates a live dashboard.

**The Data Flow:**

1.  **Ingestion:** Python logic generates synthetic traffic patterns (normal users vs. DDoS/Bot attacks).
2.  **Processing (AWS Lambda):** A serverless function wakes up on a schedule (Cron), ingests the micro-batch, and applies a sliding window aggregation algorithm.
3.  **Storage (AWS S3):** Processed insights are written atomically to an S3 Data Lake, serving as a highly available "Serverless Database."
4.  **Presentation (React):** A decoupled frontend polls S3 for real-time updates, ensuring the UI remains responsive even if the backend is under heavy load.

---

## ðŸ›  Technical Skills Showcase

This project explicitly demonstrates competency in the **Modern Data Stack**:

| Domain | Technologies & Patterns |
| :--- | :--- |
| **Cloud Infrastructure** | AWS Lambda, AWS S3, IAM Roles, EventBridge |
| **DevOps & CI/CD** | GitHub Actions, Pytest (Unit Testing), Automated Rollouts |
| **Infrastructure as Code** | Serverless Framework (YAML), CloudFormation |
| **Data Engineering** | Micro-batch processing, Windowed Aggregation, Python (Pandas/Boto3) |
| **Frontend Integration** | React.js, Polling Architecture, Decoupled State Management |

---

## ðŸš€ The "PoC Accelerator" Framework

One of the key deliverables of this project is the deployment framework itself. This repository is not just a single-use pipeline; it is a demonstration of a reusable **Infrastructure as Code (IaC)** methodology I have applied to solve complex enterprise deployment challenges.

### Case Study: Informatica IDMC

> I have successfully utilized this exact Serverless + CI/CD framework to deploy Secure Agent Runtime Environments for **Informatica IDMC (Intelligent Data Management Cloud)**.

In that scenario, the challenge was ensuring that agent runtimes were secure, compliant, and identical across regions. By adapting this framework, I achieved:

* **Immutable Infrastructure:** Replaced manual server setup with codified definitions, ensuring every Informatica Secure Agent was provisioned with identical security groups and IAM permissions.
* **Audit Compliance:** The Git-based workflow provided a perfect audit trail of who changed infrastructure and whenâ€”a requirement for secure enterprise environments.
* **Rapid Scale-Out:** We reduced the lead time for standing up new integration environments from **days to minutes**.

### Core Framework Benefits

* **Standardized IaC:** The `serverless.yml` pre-configures standard IAM roles and bucket policies, ensuring security compliance out of the box.
* **Built-in Quality Gates:** The CI pipeline enforces `pytest` execution before deployment, preventing broken logic from reaching the cloud.
* **Environment Agnostic:** The pipeline dynamic injection (`${sls:stage}`) allows deploying to dev, staging, and prod environments from the same codebase without code changes.

**Result:** A reproducible "Cookie Cutter" stack that accelerates the delivery of both Data Pipelines and Enterprise Infrastructure.

---

## ðŸ“‚ Repository Structure

```text
.
â”œâ”€â”€ .github/workflows/   # CI/CD Pipeline Definitions
â”‚   â””â”€â”€ deploy.yml       # GitHub Actions Workflow
â”œâ”€â”€ handler.py           # Core Application Logic (Decoupled from AWS)
â”œâ”€â”€ test_handler.py      # Unit Tests (Pytest)
â”œâ”€â”€ serverless.yml       # Infrastructure as Code (AWS CloudFormation generation)
â””â”€â”€ README.md            #
```

Documentation
```
Storage (AWS S3): Processed insights are written atomically to an S3 Data Lake, serving as a highly available "Serverless Database."
Presentation (React): A decoupled frontend polls S3 for real-time updates, ensuring the UI remains responsive even if the backend is under heavy load.
```

---

## âš™ï¸ How to Deploy

Prerequisites
AWS Account (Access Key & Secret Key)
GitHub Account
Node.js & NPM (for Serverless Framework)
1. Configure Secrets
In your GitHub Repository Settings -> Secrets and Variables -> Actions, add:
AWS_ACCESS_KEY_ID
AWS_SECRET_ACCESS_KEY
2. Push to Deploy
This project follows GitOps principles. To deploy updates, simply push to the main branch:
```
git add .
git commit -m "Update anomaly detection threshold"
git push origin main
```

What happens next?
```
GitHub Actions spins up a runner.

CI Phase: Runs test_handler.py to verify logic.

CD Phase: Installs Serverless Framework (v3).

Provisioning: Deploys Lambda functions and configures S3 Buckets via CloudFormation.
```

### ðŸ§ª Local Development
You can run the logic and tests locally without an AWS account:

### Install dependencies
```pip install pytest boto3```

### Run the test suite
```pytest test_handler.py```


